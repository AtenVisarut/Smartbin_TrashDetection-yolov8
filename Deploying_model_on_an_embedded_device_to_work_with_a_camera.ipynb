{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Deploying a trained model on an embedded device to work with a camera.**"
      ],
      "metadata": {
        "id": "zWr3BbqdDdSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import cv2  # OpenCV library for video and image processing\n",
        "import torch  # PyTorch, the underlying framework for the YOLO model\n",
        "import argparse  # For parsing command-line arguments\n",
        "from ultralytics import YOLO  # YOLO model library\n",
        "import RPi.GPIO as GPIO  # For controlling Raspberry Pi GPIO pins\n",
        "import time  # For timing control\n",
        "\n",
        "# Motor control setup\n",
        "GPIO.setmode(GPIO.BCM)\n",
        "MOTOR_PINS = {\n",
        "    \"recyclable\": 17,\n",
        "    \"hazardous\": 18,\n",
        "    \"biodegradable\": 22,\n",
        "    \"general\": 23\n",
        "}\n",
        "\n",
        "# Initialize GPIO pins\n",
        "for pin in MOTOR_PINS.values():\n",
        "    GPIO.setup(pin, GPIO.OUT)\n",
        "    GPIO.output(pin, GPIO.LOW)\n",
        "\n",
        "def open_bin(bin_type, duration=3):\n",
        "    \"\"\"Control servo to open specific trash bin\"\"\"\n",
        "    print(f\"Opening {bin_type} bin\")\n",
        "    GPIO.output(MOTOR_PINS[bin_type], GPIO.HIGH)\n",
        "    time.sleep(duration)\n",
        "    GPIO.output(MOTOR_PINS[bin_type], GPIO.LOW)\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"\n",
        "    Parses command-line arguments for the script.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Smart Trash Bin Detection System\")\n",
        "    parser.add_argument('--model', type=str, default='best.pt', help='Path to YOLO model')\n",
        "    parser.add_argument('--conf', type=float, default=0.8, help='Confidence threshold (default: 0.8)')\n",
        "    parser.add_argument('--camera', type=int, default=0, help='Camera index (default: 0)')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the object detection program.\n",
        "    \"\"\"\n",
        "    args = parse_args()\n",
        "\n",
        "    # Class mapping dictionary\n",
        "    CLASS_MAP = {\n",
        "        0: \"recyclable\",    # glass\n",
        "        1: \"recyclable\",    # metal\n",
        "        2: \"recyclable\",    # paper\n",
        "        3: \"recyclable\",    # plastic\n",
        "        4: \"hazardous\",     # battery\n",
        "        5: \"recyclable\",    # cardboard\n",
        "        6: \"general\",       # clothes\n",
        "        7: \"biodegradable\", # organic\n",
        "        8: \"general\"        # shoes\n",
        "    }\n",
        "\n",
        "    # Load the YOLO model\n",
        "    print(f\"Loading model {args.model}...\")\n",
        "    model = YOLO(args.model)\n",
        "\n",
        "    # Open the webcam\n",
        "    cap = cv2.VideoCapture(args.camera)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open webcam at index {args.camera}\")\n",
        "        return\n",
        "\n",
        "    # Main processing loop\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Error: Could not read frame\")\n",
        "            break\n",
        "\n",
        "        frame_resized = cv2.resize(frame, (640, 480))\n",
        "        results = model(frame_resized)\n",
        "\n",
        "        detected_classes = set()  # To track detected classes in current frame\n",
        "\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                conf = box.conf[0].item()\n",
        "                cls = int(box.cls[0].item())\n",
        "\n",
        "                # Only process detections above confidence threshold\n",
        "                if conf >= args.conf:\n",
        "                    detected_classes.add(cls)\n",
        "\n",
        "                    # Get coordinates and draw bounding box\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                    label = f\"{CLASS_MAP.get(cls, 'unknown')} ({conf:.2f})\"\n",
        "\n",
        "                    cv2.rectangle(frame_resized, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                    cv2.putText(frame_resized, label, (x1, y1 - 10),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "        # Open corresponding bin if any detection meets confidence threshold\n",
        "        if detected_classes:\n",
        "            # Get the most confident detection\n",
        "            main_class = max(detected_classes, key=lambda x: box.conf[0].item())\n",
        "            bin_type = CLASS_MAP.get(main_class, \"general\")\n",
        "            open_bin(bin_type)\n",
        "\n",
        "        cv2.imshow(\"Smart Trash Bin Detection\", frame_resized)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Cleanup\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    GPIO.cleanup()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "An2rZnVZEvnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "โครงสร้างของโค้ด\n",
        "การนำเข้าไลบรารี (Imports):\n",
        "\n",
        "cv2: คือไลบรารี OpenCV ใช้สำหรับจัดการกับวิดีโอและรูปภาพ เช่น การจับภาพจากกล้อง การปรับขนาดภาพ และการวาดกรอบ\n",
        "\n",
        "torch: คือไลบรารี PyTorch ซึ่งเป็นพื้นฐานของโมเดล YOLO ที่ใช้ในการคำนวณและประมวลผลข้อมูล\n",
        "\n",
        "argparse: ใช้สำหรับจัดการกับอาร์กิวเมนต์ที่ส่งเข้ามาทางคอมมานด์ไลน์ ทำให้สามารถกำหนดค่าต่างๆ เช่น ชื่อโมเดลหรือความแม่นยำได้ง่ายขึ้น\n",
        "\n",
        "ultralytics: เป็นไลบรารีที่ใช้โมเดล YOLO ทำให้การเรียกใช้งานโมเดลทำได้ง่าย\n",
        "\n",
        "ฟังก์ชัน parse_args():\n",
        "\n",
        "ฟังก์ชันนี้จะกำหนดพารามิเตอร์ที่สามารถปรับเปลี่ยนได้เมื่อรันโค้ด เช่น:\n",
        "\n",
        "--model: ชื่อไฟล์โมเดล YOLO (ค่าเริ่มต้นคือ yolov8n.pt)\n",
        "\n",
        "--conf: ค่าความแม่นยำขั้นต่ำที่ยอมรับได้ (confidence threshold) เพื่อกรองผลลัพธ์ที่ไม่น่าเชื่อถือ (ค่าเริ่มต้นคือ 0.25)\n",
        "\n",
        "--camera: หมายเลขกล้องที่ต้องการใช้งาน (ค่าเริ่มต้นคือ 0 ซึ่งมักจะเป็นกล้องหลัก)\n",
        "\n",
        "ฟังก์ชัน main():\n",
        "\n",
        "เป็นฟังก์ชันหลักที่รันโปรแกรม\n",
        "\n",
        "args = parse_args(): เรียกใช้ฟังก์ชันด้านบนเพื่อรับค่าพารามิเตอร์ต่างๆ\n",
        "\n",
        "model = YOLO(args.model): โหลดโมเดล YOLO ที่ระบุ\n",
        "\n",
        "cap = cv2.VideoCapture(args.camera): เปิดการใช้งานกล้องเว็บแคม\n",
        "\n",
        "while True:: สร้างลูปไม่รู้จบเพื่อประมวลผลวิดีโอทีละเฟรม\n",
        "\n",
        "ret, frame = cap.read(): อ่านเฟรมจากกล้อง\n",
        "\n",
        "frame_resized = cv2.resize(...): ปรับขนาดเฟรมให้เล็กลงเพื่อความเร็วในการประมวลผล\n",
        "\n",
        "results = model(frame_resized): ส่งเฟรมที่ปรับขนาดแล้วเข้าไปในโมเดล YOLO เพื่อตรวจจับวัตถุ\n",
        "\n",
        "for result in results:: วนลูปเพื่อดูผลลัพธ์ของแต่ละวัตถุที่ตรวจจับได้\n",
        "\n",
        "cv2.rectangle(...) และ cv2.putText(...): วาดกรอบสี่เหลี่ยมและข้อความระบุคลาสและความแม่นยำลงบนเฟรม\n",
        "\n",
        "cv2.imshow(...): แสดงผลเฟรมที่มีกรอบวัตถุ\n",
        "\n",
        "if cv2.waitKey(1) & 0xFF == ord('q'):: กดปุ่ม q เพื่อออกจากโปรแกรม\n",
        "\n",
        "cap.release() และ cv2.destroyAllWindows(): ปิดการใช้งานกล้องและหน้าต่างแสดงผลเมื่อโปรแกรมจบการทำงาน"
      ],
      "metadata": {
        "id": "aYEGfhKEFNIs"
      }
    }
  ]
}